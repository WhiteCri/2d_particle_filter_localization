{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q98UeUjRdyG9"
      },
      "source": [
        "# Image Classification with Convolution Neural Network (CNN) Assignment\n",
        "\n",
        "### NOTICE: Please DO NOT MODIFY `print()` method on the assignment \n",
        "#### You can add some `print()` methods to check whether it works, but please REMOVE THEM BEFORE SUBMISSION.\n",
        "\n",
        "1. Construct Kaggle Dataset \n",
        "2. Construct a simple CNN\n",
        "3. Set hyperparameters (optimizer, criterion, num epochs)\n",
        "4. Write train / validate code\n",
        "5. Submission guidelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CpJVmq7T1RNr"
      },
      "outputs": [],
      "source": [
        "# Import libraries to use for Deep Learning \n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.io import read_image\n",
        "from torchsummary import summary\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os \n",
        "\n",
        "import cv2 as cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "yV-6tSNBwzBL",
        "outputId": "82c25cd0-ebd7-4f9a-80a7-82256104891f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rctM1HDoc24XOcRzsYyTSavaFrvuoKZc\n",
            "To: /content/archive.zip\n",
            "100% 500M/500M [00:03<00:00, 140MB/s]\n",
            "Archive:  ./archive.zip\n",
            "replace ./sports/EfficientNetB3-sports-0.97.h5? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace ./sports/class_dict.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace ./sports/class_dict.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace ./sports/images to predict/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!pip install gdown && gdown 'https://drive.google.com/uc?id=1rctM1HDoc24XOcRzsYyTSavaFrvuoKZc' && unzip ./archive.zip -d ./sports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9counoSleNDc"
      },
      "source": [
        "#1. (Assignment) Construct Kaggle Dataset\n",
        "\n",
        "- Please construct custom dataset dealt in the class.\n",
        "- Do not use `torch.utils.data.ImageFolder`.\n",
        "- The structure of Custom Dataset follows \n",
        "- Tips) use `sports.csv` files to get data. (it contains filepath, labels and which dataset each data belongs to)\n",
        "- Tips) use `class_dict.csv` to get the index of each class - numeric values, not string.\n",
        "- Tips) there are some grayscale (1-channel) images. I recommend to use `cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)` to make it 3-channel image.\n",
        "\n",
        "```\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    # Inherit torch.utils.data.Dataset class\n",
        "\n",
        "    def __init__(self,):\n",
        "        # Initialize the dataset (handling data paths, check input and target data, data augmentation, etc.)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of data or sample in dataset \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Return the input and target by index\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I3uMdcUBshYg"
      },
      "outputs": [],
      "source": [
        "### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, transform=None):\n",
        "      # Initialize the dataset (handling data paths, check input and target data, data augmentation, etc.)\n",
        "      if (dataset != 'train') and (dataset != 'valid') and (dataset != 'test'):\n",
        "        print('error!')\n",
        "\n",
        "      label_dict = {}\n",
        "      label_df = pd.read_csv('./sports/class_dict.csv') # ex: class_index,class,height,width,scale by\n",
        "                                                              # 0,air hockey,150,150,1\n",
        "      for index, row in label_df.iterrows():\n",
        "        label_dict[row['class']] = row['class_index']\n",
        "\n",
        "      data_dict = {}\n",
        "      data_df = pd.read_csv('./sports/sports.csv') #                   filepaths           labels data set\n",
        "                                                     #0         train/air hockey/001.jpg       air hockey    train\n",
        "      self.data = []\n",
        "      for index, row in data_df.iterrows():\n",
        "        if row['data set'] == dataset:\n",
        "          path = os.path.join('sports', row['filepaths'])\n",
        "          x = Image.open(path).convert('RGB')\n",
        "          if transform:\n",
        "            x = transform(x)\n",
        "          y = label_dict[row['labels']]\n",
        "          self.data.append((x, y))\n",
        "\n",
        "    def __len__(self):\n",
        "      # Return the number of data or sample in dataset \n",
        "      return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      return self.data[index]\n",
        "    \n",
        "### END OF THE CODE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DFe-GEJfAabt"
      },
      "outputs": [],
      "source": [
        "### PLEASE WRITE YOUR CODE BELOW.\n",
        "transform=transforms.ToTensor()\n",
        "\n",
        "train_dataset = CustomDataset('train', transform)\n",
        "valid_dataset = CustomDataset('valid', transform)\n",
        "test_dataset  = CustomDataset('test', transform)\n",
        "\n",
        "### YOU CAN USE ANY TRANSFORMS YOU WANT. MAKE IT RUNNABLE!\n",
        "\n",
        "### NOTE: Fixed errata - changed train_dataloader, valid_dataloader, test_dataloader to train_loader, valid_loader, test_loader by Seungwoo\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "### END OF THE CODE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpsxtveWl-bb"
      },
      "source": [
        "##2. (Assignment) Construct a network - Simple CNN\n",
        "\n",
        "- Please construct 4 convolution blocks with following sequences.\n",
        "\n",
        "\n",
        "```\n",
        "first layer = [2D Conv -> BatchNorm -> ReLU -> Dropout -> Pooling]\n",
        "\n",
        "- 2D Convolution with 3x3 kernel size, returns output dimension of 16, use stride and padding = 1.\n",
        "- use whatever pooling you want with 2x2 kernel size and stride of 2.\n",
        "\n",
        "second layer = [2D Conv -> BatchNorm -> ReLU -> Dropout -> Pooling]\n",
        "\n",
        "- 2D Convolution with 3x3 kernel size, returns output dimension of 32, use stride and padding = 1.\n",
        "- use whatever pooling you want with 2x2 kernel size and stride of 2.\n",
        "\n",
        "thrid layer = [2D Conv -> BatchNorm -> ReLU -> Dropout -> Pooling]\n",
        "\n",
        "- 2D Convolution with 3x3 kernel size, returns output dimension of 64, use stride and padding = 1.\n",
        "- use whatever pooling you want with 2x2 kernel size and stride of 2.\n",
        "\n",
        "fourth layer = [2D Conv -> BatchNorm -> ReLU -> Dropout -> Pooling]\n",
        "\n",
        "- 2D Convolution with 3x3 kernel size, returns output dimension of 128, use stride and padding = 1.\n",
        "- use whatever pooling you want with 2x2 kernel size and stride of 2.\n",
        "\n",
        "classifier = [Linear -> ReLU -> Linear]\n",
        "\n",
        "- flatten the output tensor.\n",
        "- first linear layer returns output dimension of 5012\n",
        "- second linear layer returns output dimension of number of classes\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3-HboBkFhDaB"
      },
      "outputs": [],
      "source": [
        "### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3,\n",
        "                               stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),                   \n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,\n",
        "                               stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),                   \n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,\n",
        "                               stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),                   \n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,\n",
        "                               stride=1, padding=1),\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2),                   \n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "          nn.Linear(in_features=25088, out_features=5012),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(in_features=5012, out_features=num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "### END OF THE CODE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5VYxN3gSlCJ",
        "outputId": "5095c434-6989-4aad-8286-a128fae411cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]             448\n",
            "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
            "              ReLU-3         [-1, 16, 224, 224]               0\n",
            "           Dropout-4         [-1, 16, 224, 224]               0\n",
            "         AvgPool2d-5         [-1, 16, 112, 112]               0\n",
            "            Conv2d-6         [-1, 32, 112, 112]           4,640\n",
            "       BatchNorm2d-7         [-1, 32, 112, 112]              64\n",
            "              ReLU-8         [-1, 32, 112, 112]               0\n",
            "           Dropout-9         [-1, 32, 112, 112]               0\n",
            "        AvgPool2d-10           [-1, 32, 56, 56]               0\n",
            "           Conv2d-11           [-1, 64, 56, 56]          18,496\n",
            "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
            "             ReLU-13           [-1, 64, 56, 56]               0\n",
            "          Dropout-14           [-1, 64, 56, 56]               0\n",
            "        AvgPool2d-15           [-1, 64, 28, 28]               0\n",
            "           Conv2d-16          [-1, 128, 28, 28]          73,856\n",
            "      BatchNorm2d-17          [-1, 128, 28, 28]             256\n",
            "             ReLU-18          [-1, 128, 28, 28]               0\n",
            "          Dropout-19          [-1, 128, 28, 28]               0\n",
            "        AvgPool2d-20          [-1, 128, 14, 14]               0\n",
            "           Linear-21                 [-1, 5012]     125,746,068\n",
            "             ReLU-22                 [-1, 5012]               0\n",
            "           Linear-23                  [-1, 100]         501,300\n",
            "================================================================\n",
            "Total params: 126,345,288\n",
            "Trainable params: 126,345,288\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 48.89\n",
            "Params size (MB): 481.97\n",
            "Estimated Total Size (MB): 531.43\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "### NOTE: Fixed errata - changed the below codes by Seungwoo\n",
        "### model = SimpleCNN(in_channels=3, num_classes=100).to(device)\n",
        "### summary(model, (3, 256, 256), device='cuda') \n",
        "\n",
        "model = SimpleCNN(in_channels=3, num_classes=100).cuda()\n",
        "summary(model, (3, 224, 224), device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj3281v__AlY"
      },
      "source": [
        "##3. (Assignment) Set hyperparameters\n",
        "\n",
        "- Set the total number of epochs to be 50 and the learning rate to be 0.001.\n",
        "\n",
        "- Use any optimizers you want. Please refer [here](https://pytorch.org/docs/stable/optim.html) for furter details.\n",
        "    - Remember different optimizers have different hyperparameters.\n",
        "- Set the loss function to be cross entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8pCDa2YK4fqv"
      },
      "outputs": [],
      "source": [
        "### PLEASE FILL OUT THE HYPERPARAMETERS\n",
        "### NOTE THAT YOU SHOULD SET DIFFERENT PARAMETERS FOR DIFFERENT OPTIMIZERS.\n",
        "\n",
        "lr = 0.001\n",
        "epochs = 50\n",
        "\n",
        "## OPTIMIZER HYPERPARAMETERS - PLEASE ADD/REMOVE DEPENDS ON OPTIMIZER.\n",
        "betas = 0\n",
        "momentum = 0.9\n",
        "\n",
        "## WHEN USING GPU, PUT `.cuda()` on model and criterion.\n",
        "\n",
        "model = SimpleCNN(in_channels=3, num_classes=100).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS29-fIf4jrq"
      },
      "source": [
        "##4. (Assignment) Write train / validation code\n",
        "\n",
        "- For each epoch, we train and validate the model.\n",
        "- Note that the validation dataset is not included in test set. \n",
        "- Please refer to the following procedure:\n",
        "\n",
        "\n",
        "    for each epoch:\n",
        "        model.train()\n",
        "        get input and target data from train loader\n",
        "        \n",
        "        optmizer.zero_grad()             # reset the gradient \n",
        "        pred = model(input)\n",
        "\n",
        "        loss = criterion(pred, target)   # compute the loss\n",
        "        loss.backward()                  # backprop\n",
        "        optimizer.step()                 # update the model weights\n",
        "\n",
        "        model.eval()                     # set the evaluation mode (turn off batchnorm, dropout)\n",
        "        with torch.no_grad():\n",
        "            get the input and target data from validation loader\n",
        "\n",
        "            pred = model(input)\n",
        "            compute the validation loss  # Optional \n",
        "            calculate the validation accuracy\n",
        "            save the model w.r.t. validation accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TeRQcYZ951WH"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, criterion, data_loader, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for idx, batch in enumerate(data_loader):\n",
        "        img, target = batch[0].cuda(), batch[1].cuda()\n",
        "\n",
        "        ### PLEASE WRITE YOUR CODE BELOW.\n",
        "        # Initialize the optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make a prediction\n",
        "        output = model(img)\n",
        "\n",
        "        # Calculate loss with prediction and target\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Compute the gradient\n",
        "        loss.backward()\n",
        "\n",
        "        # Update Parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        ### END OF THE CODE.\n",
        "\n",
        "        total_loss += loss.item() \n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch + 1, idx * img.size(0), len(data_loader.dataset),\n",
        "                100. * idx * img.size(0) / len(data_loader.dataset), \n",
        "                loss.data))\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_acc = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(data_loader):\n",
        "            img, target = batch[0].cuda(), batch[1].cuda()\n",
        "\n",
        "            ### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "            # Make a prediction\n",
        "            output = model(img)\n",
        "\n",
        "            # Calculate validation loss (although it is optional)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # Get the right prediction - make sure naming the prediction as 'predicted' \n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "            ### END OF THE CODE.\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_acc += (predicted == target).sum().item()\n",
        "\n",
        "        total_val_acc = val_acc / len(data_loader.dataset)\n",
        "        print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            val_loss / len(data_loader), val_acc, len(data_loader.dataset),\n",
        "            100. * total_val_acc))\n",
        "    \n",
        "    return total_val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PE6MMpqVzpKH"
      },
      "outputs": [],
      "source": [
        "def test(model, data_loader):\n",
        "    model.eval()\n",
        "    test_acc = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(data_loader):\n",
        "            img, target = batch[0].cuda(), batch[1].cuda()\n",
        "\n",
        "            ### PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "            # Make a prediction\n",
        "            output = model(img)\n",
        "\n",
        "            # Get the right prediction - make sure naming the prediction as 'predicted' \n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "            ### END OF THE CODE.\n",
        "\n",
        "        print('\\n Test set:  Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_acc, len(data_loader.dataset),\n",
        "            100. * test_acc / len(data_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5EaA6sGo2b3",
        "outputId": "10d2d246-451c-466d-daa9-668c51e0aaa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/13572 (0%)]\tLoss: 3.643844\n",
            "Train Epoch: 1 [640/13572 (5%)]\tLoss: 3.518664\n",
            "Train Epoch: 1 [1280/13572 (9%)]\tLoss: 3.610075\n",
            "Train Epoch: 1 [1920/13572 (14%)]\tLoss: 3.448734\n",
            "Train Epoch: 1 [2560/13572 (19%)]\tLoss: 3.578585\n",
            "Train Epoch: 1 [3200/13572 (24%)]\tLoss: 3.196797\n",
            "Train Epoch: 1 [3840/13572 (28%)]\tLoss: 3.469079\n",
            "Train Epoch: 1 [4480/13572 (33%)]\tLoss: 3.433546\n",
            "Train Epoch: 1 [5120/13572 (38%)]\tLoss: 3.391923\n",
            "Train Epoch: 1 [5760/13572 (42%)]\tLoss: 3.444098\n",
            "Train Epoch: 1 [6400/13572 (47%)]\tLoss: 3.161500\n",
            "Train Epoch: 1 [7040/13572 (52%)]\tLoss: 3.308374\n",
            "Train Epoch: 1 [7680/13572 (57%)]\tLoss: 3.470518\n",
            "Train Epoch: 1 [8320/13572 (61%)]\tLoss: 3.089716\n",
            "Train Epoch: 1 [8960/13572 (66%)]\tLoss: 3.405200\n",
            "Train Epoch: 1 [9600/13572 (71%)]\tLoss: 2.916322\n",
            "Train Epoch: 1 [10240/13572 (75%)]\tLoss: 3.266115\n",
            "Train Epoch: 1 [10880/13572 (80%)]\tLoss: 3.198617\n",
            "Train Epoch: 1 [11520/13572 (85%)]\tLoss: 3.266559\n",
            "Train Epoch: 1 [12160/13572 (90%)]\tLoss: 3.114872\n",
            "Train Epoch: 1 [12800/13572 (94%)]\tLoss: 3.014773\n",
            "Train Epoch: 1 [13440/13572 (99%)]\tLoss: 3.308653\n",
            "Train Epoch: 2 [0/13572 (0%)]\tLoss: 3.052622\n",
            "Train Epoch: 2 [640/13572 (5%)]\tLoss: 3.096941\n",
            "Train Epoch: 2 [1280/13572 (9%)]\tLoss: 3.265326\n",
            "Train Epoch: 2 [1920/13572 (14%)]\tLoss: 3.110065\n",
            "Train Epoch: 2 [2560/13572 (19%)]\tLoss: 2.938156\n",
            "Train Epoch: 2 [3200/13572 (24%)]\tLoss: 2.979285\n",
            "Train Epoch: 2 [3840/13572 (28%)]\tLoss: 2.982687\n",
            "Train Epoch: 2 [4480/13572 (33%)]\tLoss: 3.099036\n",
            "Train Epoch: 2 [5120/13572 (38%)]\tLoss: 2.792934\n",
            "Train Epoch: 2 [5760/13572 (42%)]\tLoss: 2.872456\n",
            "Train Epoch: 2 [6400/13572 (47%)]\tLoss: 2.834080\n",
            "Train Epoch: 2 [7040/13572 (52%)]\tLoss: 2.932692\n",
            "Train Epoch: 2 [7680/13572 (57%)]\tLoss: 2.961258\n",
            "Train Epoch: 2 [8320/13572 (61%)]\tLoss: 2.954863\n",
            "Train Epoch: 2 [8960/13572 (66%)]\tLoss: 2.955992\n",
            "Train Epoch: 2 [9600/13572 (71%)]\tLoss: 2.817391\n",
            "Train Epoch: 2 [10240/13572 (75%)]\tLoss: 2.404336\n",
            "Train Epoch: 2 [10880/13572 (80%)]\tLoss: 3.052421\n",
            "Train Epoch: 2 [11520/13572 (85%)]\tLoss: 2.641133\n",
            "Train Epoch: 2 [12160/13572 (90%)]\tLoss: 2.820469\n",
            "Train Epoch: 2 [12800/13572 (94%)]\tLoss: 2.495398\n",
            "Train Epoch: 2 [13440/13572 (99%)]\tLoss: 3.045270\n",
            "Train Epoch: 3 [0/13572 (0%)]\tLoss: 2.554169\n",
            "Train Epoch: 3 [640/13572 (5%)]\tLoss: 2.652784\n",
            "Train Epoch: 3 [1280/13572 (9%)]\tLoss: 2.601593\n",
            "Train Epoch: 3 [1920/13572 (14%)]\tLoss: 2.332895\n",
            "Train Epoch: 3 [2560/13572 (19%)]\tLoss: 2.503462\n",
            "Train Epoch: 3 [3200/13572 (24%)]\tLoss: 2.628854\n",
            "Train Epoch: 3 [3840/13572 (28%)]\tLoss: 2.663349\n",
            "Train Epoch: 3 [4480/13572 (33%)]\tLoss: 2.680429\n",
            "Train Epoch: 3 [5120/13572 (38%)]\tLoss: 2.452274\n",
            "Train Epoch: 3 [5760/13572 (42%)]\tLoss: 2.390586\n",
            "Train Epoch: 3 [6400/13572 (47%)]\tLoss: 2.540481\n",
            "Train Epoch: 3 [7040/13572 (52%)]\tLoss: 2.290555\n",
            "Train Epoch: 3 [7680/13572 (57%)]\tLoss: 2.641556\n",
            "Train Epoch: 3 [8320/13572 (61%)]\tLoss: 2.636847\n",
            "Train Epoch: 3 [8960/13572 (66%)]\tLoss: 2.463205\n",
            "Train Epoch: 3 [9600/13572 (71%)]\tLoss: 2.162913\n",
            "Train Epoch: 3 [10240/13572 (75%)]\tLoss: 2.689012\n",
            "Train Epoch: 3 [10880/13572 (80%)]\tLoss: 2.351380\n",
            "Train Epoch: 3 [11520/13572 (85%)]\tLoss: 2.706179\n",
            "Train Epoch: 3 [12160/13572 (90%)]\tLoss: 2.507558\n",
            "Train Epoch: 3 [12800/13572 (94%)]\tLoss: 2.899199\n",
            "Train Epoch: 3 [13440/13572 (99%)]\tLoss: 2.360845\n",
            "Train Epoch: 4 [0/13572 (0%)]\tLoss: 2.232297\n",
            "Train Epoch: 4 [640/13572 (5%)]\tLoss: 2.439369\n",
            "Train Epoch: 4 [1280/13572 (9%)]\tLoss: 2.393187\n",
            "Train Epoch: 4 [1920/13572 (14%)]\tLoss: 2.034182\n",
            "Train Epoch: 4 [2560/13572 (19%)]\tLoss: 2.289529\n",
            "Train Epoch: 4 [3200/13572 (24%)]\tLoss: 2.127574\n",
            "Train Epoch: 4 [3840/13572 (28%)]\tLoss: 2.182152\n",
            "Train Epoch: 4 [4480/13572 (33%)]\tLoss: 2.236769\n",
            "Train Epoch: 4 [5120/13572 (38%)]\tLoss: 2.468261\n",
            "Train Epoch: 4 [5760/13572 (42%)]\tLoss: 1.848000\n",
            "Train Epoch: 4 [6400/13572 (47%)]\tLoss: 2.226925\n",
            "Train Epoch: 4 [7040/13572 (52%)]\tLoss: 2.200829\n",
            "Train Epoch: 4 [7680/13572 (57%)]\tLoss: 2.220638\n",
            "Train Epoch: 4 [8320/13572 (61%)]\tLoss: 2.177042\n",
            "Train Epoch: 4 [8960/13572 (66%)]\tLoss: 2.131522\n",
            "Train Epoch: 4 [9600/13572 (71%)]\tLoss: 2.035744\n",
            "Train Epoch: 4 [10240/13572 (75%)]\tLoss: 2.309820\n",
            "Train Epoch: 4 [10880/13572 (80%)]\tLoss: 2.356263\n",
            "Train Epoch: 4 [11520/13572 (85%)]\tLoss: 1.996464\n",
            "Train Epoch: 4 [12160/13572 (90%)]\tLoss: 2.069525\n",
            "Train Epoch: 4 [12800/13572 (94%)]\tLoss: 2.025635\n",
            "Train Epoch: 4 [13440/13572 (99%)]\tLoss: 2.511550\n",
            "Train Epoch: 5 [0/13572 (0%)]\tLoss: 1.900391\n",
            "Train Epoch: 5 [640/13572 (5%)]\tLoss: 2.184661\n",
            "Train Epoch: 5 [1280/13572 (9%)]\tLoss: 1.899504\n",
            "Train Epoch: 5 [1920/13572 (14%)]\tLoss: 2.000672\n",
            "Train Epoch: 5 [2560/13572 (19%)]\tLoss: 1.848527\n",
            "Train Epoch: 5 [3200/13572 (24%)]\tLoss: 1.941108\n",
            "Train Epoch: 5 [3840/13572 (28%)]\tLoss: 1.887345\n",
            "Train Epoch: 5 [4480/13572 (33%)]\tLoss: 2.230162\n",
            "Train Epoch: 5 [5120/13572 (38%)]\tLoss: 2.033085\n",
            "Train Epoch: 5 [5760/13572 (42%)]\tLoss: 1.898416\n",
            "Train Epoch: 5 [6400/13572 (47%)]\tLoss: 2.276952\n",
            "Train Epoch: 5 [7040/13572 (52%)]\tLoss: 1.970886\n",
            "Train Epoch: 5 [7680/13572 (57%)]\tLoss: 2.075144\n"
          ]
        }
      ],
      "source": [
        "### NOTE: Fix errata - changed for epoch in range(2) by Seungwoo\n",
        "train_losses = []\n",
        "validation_accuracies = []\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    ### PLEASE WRITE YOUR CODE BELOW.\n",
        "    \n",
        "    # Train your model with train dataloader\n",
        "    train_loss = train(model, optimizer, criterion, train_loader, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validate your model with validation dataloader\n",
        "    validation_accuracy = (model, criterion, valid_loader)\n",
        "    validation_accuracies.append(validation_accuracy)\n",
        "    ### END OF THE CODE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-h4GbViAtXn"
      },
      "outputs": [],
      "source": [
        "# PLEASE WRITE YOUR CODE BELOW.\n",
        "\n",
        "# Test your model with test dataloader\n",
        "test(model, criterion, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9W5_Li880FX"
      },
      "source": [
        "##5. Submission\n",
        "\n",
        "- Please EXECUTE the below cell and save your file with the output.\n",
        "- Do not create any other cells below.\n",
        "- Please save the assignment WITHOUT changing the file name, which should be **CNN_assignment.ipynb**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeH2Q4l3BTzt"
      },
      "outputs": [],
      "source": [
        "### PLEASE EXECUTE THE FOLLOWING CELL BEFORE SUBMITTING YOUR CODE\n",
        "\n",
        "### DO NOT MODIFY THIS CELL\n",
        "print(train_dataset[0][0].size())\n",
        "print(model(torch.rand(1, 3, 224, 224, device='cuda')).size())\n",
        "test(model, test_loader)\n",
        "### DO NOT MODIFY THIS CELL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB4vSntnJ2AN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}